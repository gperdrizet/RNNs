{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3378c30f",
   "metadata": {},
   "source": [
    "# Introduction to RNNs: learning the alphabet\n",
    "\n",
    "A simple example to understand how Recurrent Neural Networks learn sequential patterns.\n",
    "\n",
    "## Key concepts\n",
    "\n",
    "- **Sequence learning**: RNNs process input one step at a time, maintaining a \"memory\" (hidden state) of what they've seen.\n",
    "- **Next-character prediction**: Given a sequence like `['a', 'b', 'c']`, predict the next character (`'d'`).\n",
    "- **Hidden state**: The internal memory that carries information from previous timesteps (or indexes) in a sequence.\n",
    "\n",
    "## How the RNN processes a sequence\n",
    "\n",
    "Given input `['a', 'b', 'c']`, the RNN predicts `'d'`:\n",
    "\n",
    "```text\n",
    "\n",
    "                     ┌─◀──────┐ 'h₁', then 'h₂'\n",
    "                     │        ▲ \n",
    "                     ▼        |\n",
    "                    ┌──────────┐\n",
    "                    |   RNN    |         ┌───────┐\n",
    "'a', then 'b', ────▶| (hidden  |──'h₃'──▶│ Dense │───▶ 'c'\n",
    "   then 'c'         | state h) |         └───────┘ \n",
    "                    └──────────┘\n",
    "\n",
    "\n",
    "h₁ = RNN('a', h₀)        # h₁ \"knows\" about 'a'\n",
    "h₂ = RNN('b', h₁)        # h₂ \"knows\" about 'a', 'b'  \n",
    "h₃ = RNN('c', h₂)        # h₃ \"knows\" about 'a', 'b', 'c'\n",
    "output = Dense(h₃) → 'd' # Final hidden state predicts next char\n",
    "```\n",
    "\n",
    "The same RNN weights are used at each step within a sequence — only the hidden state changes.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f911a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=300\n",
    "batch_size=4\n",
    "\n",
    "# Force CPU only\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7f84e",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Create the alphabet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alphabet mapping\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "char_to_idx = {c: i for i, c in enumerate(alphabet)}\n",
    "idx_to_char = {i: c for i, c in enumerate(alphabet)}\n",
    "vocab_size = len(alphabet)\n",
    "\n",
    "print(f'Vocabulary: {alphabet}')\n",
    "\n",
    "print('\\nMappings:\\n')\n",
    "\n",
    "for key, val in char_to_idx.items():\n",
    "    print(f' {key} -> {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f58f6",
   "metadata": {},
   "source": [
    "### 1.2. Training 'freatures' & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3\n",
    "\n",
    "y = alphabet[seq_length:] + 'a'  # Wrap around: 'xyz' -> 'a'\n",
    "x = list(zip(*[alphabet[i:] for i in range(seq_length)]))\n",
    "\n",
    "print('\\nInput sequence  -> label')\n",
    "\n",
    "for features, label in zip(x, y):\n",
    "    print(f'{features} -> {label}')\n",
    "\n",
    "print(f'X shape: {np.array(x).shape}, y shape: {np.array(list(y)).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9b9c8",
   "metadata": {},
   "source": [
    "### 1.3. One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61098b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indices = np.array([[char_to_idx[c] for c in seq] for seq in x])\n",
    "y_indices = np.array([char_to_idx[c] for c in y])\n",
    "\n",
    "X_onehot = to_categorical(X_indices, num_classes=vocab_size)\n",
    "y_onehot = to_categorical(y_indices, num_classes=vocab_size)\n",
    "\n",
    "print('First sequence (one-hot):')\n",
    "\n",
    "for ele in X_onehot[0][:, :10]:\n",
    "    print(f' {(\", \").join(map(str, ele))}...')\n",
    "\n",
    "print('\\nFirst label (one-hot):')\n",
    "print(f' {(\", \").join(map(str, y_onehot[0][:10]))}...')\n",
    "\n",
    "print(f'\\nX shape (one-hot): {X_onehot.shape}')\n",
    "print(f'y shape (one-hot): {y_onehot.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a5f3c",
   "metadata": {},
   "source": [
    "## 2. Recurrent model\n",
    "\n",
    "A simple architecture:\n",
    "1. **Input**: One-hot encoded characters (26-dimensional vectors)\n",
    "2. **SimpleRNN**: Process the sequence, output final hidden state  \n",
    "3. **Dense**: Predict the next character\n",
    "\n",
    "With one-hot encoding, each input character is a vector of 26 zeros with a single 1 at the character's index position.\n",
    "\n",
    "### 2.1. Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "hidden_dim = 8 # RNN hidden state size\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(hidden_dim, input_shape=(seq_length, vocab_size)),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fba5a",
   "metadata": {},
   "source": [
    "### 2.2. Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_onehot, y_onehot,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46732ca6",
   "metadata": {},
   "source": [
    "### 2.3. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "axes[0].plot(history.history['loss'])\n",
    "axes[0].set_title('Training loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "\n",
    "axes[1].plot(history.history['accuracy'])\n",
    "axes[1].set_title('Training accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcbaad",
   "metadata": {},
   "source": [
    "## 3. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(chars, model):\n",
    "    '''Predict the next character given a sequence.'''\n",
    "\n",
    "    indices = np.array([[char_to_idx[c] for c in chars]])\n",
    "    onehot = to_categorical(indices, num_classes=vocab_size)\n",
    "    pred = model.predict(onehot, verbose=0)\n",
    "    next_idx = np.argmax(pred)\n",
    "\n",
    "    return idx_to_char[next_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "test_sequences = ['abc', 'def', 'mno', 'stu', 'wxy']\n",
    "\n",
    "print('Predictions:')\n",
    "\n",
    "for seq in test_sequences:\n",
    "    if len(seq) == seq_length and all(c in char_to_idx for c in seq):\n",
    "        pred = predict_next(seq, model)\n",
    "        print(f' {seq} -> {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
